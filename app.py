import streamlit as st
import pandas as pd
import os
import glob
import plotly.express as px
from datetime import datetime

# -----------------------------------------------------------------------------
# 1. Configuration & Constants
# -----------------------------------------------------------------------------
st.set_page_config(page_title="ìŠ¤ë§ˆíŠ¸(SM) ìˆ˜ê¸‰ ë¶„ì„ê¸°", layout="wide")

# Paths (using relative path for Streamlit Cloud deployment)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "KR_SM_Stock")
META_FILE_SECTOR = os.path.join(BASE_DIR, "ì—…ì¢…ë¶„ë¥˜.csv")
META_FILE_BASIC = os.path.join(BASE_DIR, "Basic stock info.csv")

# -----------------------------------------------------------------------------
# 2. Authentication
# -----------------------------------------------------------------------------
if 'authenticated' not in st.session_state:
    st.session_state['authenticated'] = False

def check_password():
    if st.session_state['password_input'] == "81052831":
        st.session_state['authenticated'] = True
        # Clear password from session state for security (optional but good practice)
        st.session_state['password_input'] = ""
    else:
        st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def logout():
    st.session_state['authenticated'] = False
    st.rerun()

if not st.session_state['authenticated']:
    st.title("ğŸ”’ ë¡œê·¸ì¸")
    st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", key="password_input", on_change=check_password)
    st.button("ë¡œê·¸ì¸", on_click=check_password)
    st.stop() # Stop execution if not authenticated

# -----------------------------------------------------------------------------
# 3. Main App (Authenticated)
# -----------------------------------------------------------------------------

# Logout Button in Sidebar
st.sidebar.button("ë¡œê·¸ì•„ì›ƒ", on_click=logout)

# -----------------------------------------------------------------------------
# 4. Data Loading & Processing
# -----------------------------------------------------------------------------
@st.cache_data(ttl=60)
def load_and_process_data():
    """
    Loads daily SM files, Sector info, and Basic info.
    Returns:
        df_all: Combined daily dataframe
        sector_map: Dictionary of Code -> Sector Name
        basic_info: DataFrame with current price info
    """
    # 2.1 Load Daily Files
    all_files = glob.glob(os.path.join(DATA_DIR, "*_SM stock.csv"))
    if not all_files:
        return pd.DataFrame(), {}, pd.DataFrame()

    daily_dfs = []
    for f in all_files:
        try:
            # Parse Date from filename: YYYYMMDD_SM stock.csv
            fname = os.path.basename(f)
            date_str = fname.split("_")[0]
            
            # Read CSV (cp949)
            # Force string for code column (index 0)
            df = pd.read_csv(f, encoding='cp949', header=0, dtype={0: str})
            
            # Standardize Column Names by Index to avoid encoding issues
            # Col 0: Code, 1: Name, 2: SellVol, 3: BuyVol, 4: NetBuyVol, 
            # 5: SellAmt, 6: BuyAmt, 7: NetBuyAmt (Last column)
            if len(df.columns) >= 8:
                df.columns = [
                    'Code', 'Name', 
                    'SellVol', 'BuyVol', 'NetBuyVol', 
                    'SellAmt', 'BuyAmt', 'NetBuyAmt'
                ]
            else:
                # Fallback if structure varies, try to map safely
                # Assuming first is code, second is name, last is net buy amount
                new_cols = ['Code', 'Name'] + [f'Col_{i}' for i in range(2, len(df.columns)-1)] + ['NetBuyAmt']
                df.columns = new_cols
                
            df['Date'] = date_str
            daily_dfs.append(df)
        except Exception as e:
            # st.error(f"Error reading {f}: {e}") # Suppress individual file errors to avoid clutter
            continue

    if not daily_dfs:
        return pd.DataFrame(), {}, pd.DataFrame()

    df_all = pd.concat(daily_dfs, ignore_index=True)

    # Clean Numeric Columns (remove commas and convert to float)
    num_cols = ['SellVol', 'BuyVol', 'NetBuyVol', 'SellAmt', 'BuyAmt', 'NetBuyAmt']
    for col in num_cols:
        if col in df_all.columns:
            if df_all[col].dtype == object:
                df_all[col] = df_all[col].str.replace(',', '')
            df_all[col] = pd.to_numeric(df_all[col], errors='coerce').fillna(0)
    
    # Unit Conversion: Won -> Billions (ì–µ)
    if 'NetBuyAmt' in df_all.columns:
        df_all['NetBuyAmt_100M'] = df_all['NetBuyAmt'] / 100000000
    else:
        df_all['NetBuyAmt_100M'] = 0

    if 'BuyAmt' in df_all.columns:
        df_all['BuyAmt_100M'] = df_all['BuyAmt'] / 100000000
    else:
        df_all['BuyAmt_100M'] = 0

    # 2.2 Load Metadata (Sector)
    sector_map = {}
    if os.path.exists(META_FILE_SECTOR):
        try:
            s_df = pd.read_csv(META_FILE_SECTOR, encoding='cp949', header=None, dtype={0: str})
            # Assume columns: 0=Code, 1=SectorName
            if len(s_df.columns) >= 2:
                sector_map = dict(zip(s_df.iloc[:, 0], s_df.iloc[:, 1]))
        except:
            pass

    # 2.3 Load Metadata (Basic Info)
    basic_info = pd.DataFrame()
    if os.path.exists(META_FILE_BASIC):
        try:
            # Read without assuming header names are correct due to encoding issues
            # Inspect: Col 0=Code, Col 1=Name, Col 4=Current Price
            basic_info = pd.read_csv(META_FILE_BASIC, encoding='cp949', header=0, dtype={0: str})
            
            # Rename columns by index to ensure safety
            if len(basic_info.columns) >= 5:
                # Create a clean map
                clean_basic = pd.DataFrame()
                clean_basic['Code'] = basic_info.iloc[:, 0]
                clean_basic['CurrentPrice'] = basic_info.iloc[:, 4] # Index 4 is Current Price
                
                # Clean 'CurrentPrice'
                if clean_basic['CurrentPrice'].dtype == object:
                    clean_basic['CurrentPrice'] = clean_basic['CurrentPrice'].str.replace(',', '')
                clean_basic['CurrentPrice'] = pd.to_numeric(clean_basic['CurrentPrice'], errors='coerce').fillna(0)
                
                basic_info = clean_basic
            else:
                basic_info = pd.DataFrame(columns=['Code', 'CurrentPrice'])

        except Exception as e:
            st.error(f"ê¸°ë³¸ ì •ë³´ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            basic_info = pd.DataFrame(columns=['Code', 'CurrentPrice'])

    # Map Sector to Main DF
    df_all['Sector'] = df_all['Code'].map(sector_map).fillna('Unknown')

    return df_all, sector_map, basic_info

# -----------------------------------------------------------------------------
# 5. Calculation Logic
# -----------------------------------------------------------------------------
def get_sorted_dates(df):
    return sorted(df['Date'].unique(), reverse=True)

def calc_sector_ranking(df, days):
    dates = get_sorted_dates(df)[:days]
    subset = df[df['Date'].isin(dates)]
    ranking = subset.groupby('Sector')['NetBuyAmt_100M'].sum().sort_values(ascending=False)
    # Convert Series to DataFrame for styling
    return ranking.to_frame(name='NetBuyAmt_100M')

def run_abc_strategy(df, basic_info):
    dates = get_sorted_dates(df)
    
    # Data Subsets
    df_20 = df[df['Date'].isin(dates[:20])]
    df_5 = df[df['Date'].isin(dates[:5])]
    df_3 = df[df['Date'].isin(dates[:3])]

    # A: Top 30 (20 days Sum)
    a_group = df_20.groupby(['Code', 'Name'])[['NetBuyAmt_100M', 'BuyAmt', 'BuyVol']].sum()
    top_30_a = a_group.sort_values('NetBuyAmt_100M', ascending=False).head(30)
    
    # Calculate Avg Price for A (Total Buy Amt / Total Buy Vol)
    # Note: Raw units (Won / Vol) -> Price in Won
    top_30_a['AvgPrice'] = top_30_a.apply(
        lambda x: x['BuyAmt'] / x['BuyVol'] if x['BuyVol'] > 0 else 0, axis=1
    )

    # B: Net Sell (5 days Sum < 0)
    b_group = df_5.groupby('Code')['NetBuyAmt_100M'].sum()
    b_exclude = b_group[b_group < 0].index.tolist()

    # C: Net Sell (3 days Sum < 0)
    c_group = df_3.groupby('Code')['NetBuyAmt_100M'].sum()
    c_exclude = c_group[c_group < 0].index.tolist()

    # Filter
    exclude_codes = set(b_exclude) | set(c_exclude)
    
    # Add status columns
    top_30_a['Status'] = top_30_a.index.get_level_values('Code').isin(exclude_codes)
    top_30_a['Reason'] = ''
    
    # Mark reasons for display
    def get_reason(code):
        reasons = []
        if code in b_exclude: reasons.append("5ì¼ ìœ ì¶œ")
        if code in c_exclude: reasons.append("3ì¼ ìœ ì¶œ")
        return ", ".join(reasons)
        
    top_30_a['Reason'] = [get_reason(c) for c in top_30_a.index.get_level_values('Code')]

    # Reset Index for merging
    res_df = top_30_a.reset_index()

    # Merge Current Price
    if not basic_info.empty:
        res_df = pd.merge(res_df, basic_info, on='Code', how='left')
        res_df['CurrentPrice'] = res_df['CurrentPrice'].fillna(0)
        
    # Calculate Disparity: (Current - Avg) / Avg * 100
    res_df['Disparity'] = res_df.apply(
        lambda x: ((x['CurrentPrice'] - x['AvgPrice']) / x['AvgPrice'] * 100) 
        if x['CurrentPrice'] > 0 and x['AvgPrice'] > 0 else 0.0, 
        axis=1
    )

    final = res_df[~res_df['Code'].isin(exclude_codes)].copy()
    excluded = res_df[res_df['Code'].isin(exclude_codes)].copy()
    
    return final, excluded

def get_consecutive_buys(df, days):
    dates = get_sorted_dates(df)[:days]
    subset = df[df['Date'].isin(dates)]
    
    # Pivot: Index=Code, Col=Date, Val=NetBuy
    pivot = subset.pivot_table(index=['Code', 'Name'], columns='Date', values='NetBuyAmt_100M')
    
    # Check if all columns > 0
    # Also handle missing data (NaN) as not buying -> strict consecutive check means no NaNs and > 0
    cond = (pivot > 0).all(axis=1) & (pivot.notna().all(axis=1))
    
    res = pivot[cond].copy()
    res['Total_NetBuy'] = res.sum(axis=1)
    
    return res.sort_values('Total_NetBuy', ascending=False).head(10)

# -----------------------------------------------------------------------------
# 6. UI Layout (Main Dashboard)
# -----------------------------------------------------------------------------
st.sidebar.title("ğŸš€ ë¶„ì„ ì œì–´íŒ")
if st.sidebar.button("ë¶„ì„ ì‹¤í–‰ (ë°ì´í„° ê°±ì‹ )"):
    st.cache_data.clear()
    st.rerun()

# Load Data
df, sector_map, basic_info = load_and_process_data()

if df.empty:
    st.warning("KR_SM_Stock í´ë”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

st.title("ğŸ“ˆ ìŠ¤ë§ˆíŠ¸(SM) ì „ëµ ëŒ€ì‹œë³´ë“œ")
tabs = st.tabs(["ğŸ­ ì—…ì¢… ë¶„ì„", "ğŸ¯ A-B-C ì „ëµ", "ğŸ”¥ ì—°ì† ìˆœë§¤ìˆ˜", "ğŸ” ê°œë³„ ì¢…ëª© ë¶„ì„"])

# --- Tab 1: Sector ---
with tabs[0]:
    st.header("ì—…ì¢…ë³„ ìŠ¤ë§ˆíŠ¸ ìˆ˜ê¸‰ í˜„í™© (ë‹¨ìœ„: ì–µ)")
    c1, c2, c3 = st.columns(3)
    
    with c1:
        st.subheader("ìµœê·¼ 1ì¼ ìƒìœ„")
        st.dataframe(calc_sector_ranking(df, 1).head(10).style.format("{:,.2f} ì–µ"))
    with c2:
        st.subheader("ìµœê·¼ 3ì¼ ìƒìœ„")
        st.dataframe(calc_sector_ranking(df, 3).head(10).style.format("{:,.2f} ì–µ"))
    with c3:
        st.subheader("ìµœê·¼ 5ì¼ ìƒìœ„")
        s5 = calc_sector_ranking(df, 5)
        st.dataframe(s5.head(10).style.format("{:,.2f} ì–µ"))
        
    st.divider()
    st.subheader("ğŸŒŸ ì¶”ì²œ ìœ ë§ ì„¹í„° (5ì¼ ëˆ„ì  ìƒìœ„ 2ê°œ)")
    if len(s5) >= 2:
        top_sectors = s5.index[:2].tolist()
        st.success(f"1. {top_sectors[0]}   |   2. {top_sectors[1]}")

    st.markdown("### ğŸ“Š ìƒìœ„ 5ê°œ ì—…ì¢… ì°¨íŠ¸ (5ì¼ ëˆ„ì )")
    if not s5.empty:
        fig_s5 = px.bar(s5.head(5).reset_index(), x='Sector', y='NetBuyAmt_100M', title="ìƒìœ„ 5ê°œ ì—…ì¢… ìˆœë§¤ìˆ˜ (5ì¼)", color='NetBuyAmt_100M', labels={'Sector': 'ì—…ì¢…ëª…', 'NetBuyAmt_100M': 'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)'})
        st.plotly_chart(fig_s5, use_container_width=True)

# --- Tab 2: A-B-C ---
with tabs[1]:
    st.header("A-B-C í•„í„°ë§ ì „ëµ")
    st.info("ì „ëµ ì„¤ëª…: Aê·¸ë£¹(ìµœê·¼ 20ì¼ ìŠ¤ë§ˆíŠ¸ ìˆœë§¤ìˆ˜ ìƒìœ„ 30ìœ„) ì¤‘ì—ì„œ B(ìµœê·¼ 5ì¼ ìœ ì¶œ)ì™€ C(ìµœê·¼ 3ì¼ ìœ ì¶œ) ì¢…ëª©ì„ ì œì™¸í•©ë‹ˆë‹¤.")
    
    final, excluded = run_abc_strategy(df, basic_info)
    
    # Display Config
    disp_cols = ['Code', 'Name', 'NetBuyAmt_100M', 'AvgPrice', 'CurrentPrice', 'Disparity']
    
    # Rename columns for display
    final_disp = final[disp_cols].rename(columns={
        'Code': 'ì¢…ëª©ì½”ë“œ',
        'Name': 'ì¢…ëª©ëª…',
        'NetBuyAmt_100M': 'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)',
        'AvgPrice': 'ìŠ¤ë§ˆíŠ¸í‰ë‹¨ê°€',
        'CurrentPrice': 'í˜„ì¬ê°€',
        'Disparity': 'ê´´ë¦¬ìœ¨(%)'
    })
    
    excluded_disp = excluded[['Code', 'Name', 'Reason', 'NetBuyAmt_100M']].rename(columns={
        'Code': 'ì¢…ëª©ì½”ë“œ',
        'Name': 'ì¢…ëª©ëª…',
        'Reason': 'ì œì™¸ì‚¬ìœ ',
        'NetBuyAmt_100M': 'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)'
    })

    fmt = {
        'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)': '{:,.2f} ì–µ',
        'ìŠ¤ë§ˆíŠ¸í‰ë‹¨ê°€': '{:,.0f} ì›',
        'í˜„ì¬ê°€': '{:,.0f} ì›',
        'ê´´ë¦¬ìœ¨(%)': '{:,.2f} %'
    }

    # Ensure final is a DataFrame
    if isinstance(final_disp, pd.Series):
        final_disp = final_disp.to_frame()
    
    # Ensure excluded is a DataFrame
    if isinstance(excluded_disp, pd.Series):
        excluded_disp = excluded_disp.to_frame()

    st.subheader(f"âœ… ìµœì¢… ì„ ì • ì¢…ëª© ({len(final)}ê°œ)")
    st.dataframe(final_disp.style.format(fmt, subset=['ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)', 'ìŠ¤ë§ˆíŠ¸í‰ë‹¨ê°€', 'í˜„ì¬ê°€', 'ê´´ë¦¬ìœ¨(%)']))
    
    st.subheader(f"âŒ ì œì™¸ëœ ì¢…ëª© (ìµœê·¼ ìŠ¤ë§ˆíŠ¸ ìê¸ˆ ìœ ì¶œ, {len(excluded)}ê°œ)")
    st.dataframe(excluded_disp.style.format({'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)': '{:,.2f} ì–µ'}))

# --- Tab 3: Consecutive ---
with tabs[2]:
    st.header("ì—°ì† ìˆœë§¤ìˆ˜ ì¢…ëª© (ìŠ¤ë§ˆíŠ¸ ìê¸ˆ ì§€ì† ìœ ì…)")
    periods = [1, 3, 5, 7]
    
    cols = st.columns(len(periods))
    for i, p in enumerate(periods):
        with cols[i]:
            st.markdown(f"**ìµœê·¼ {p}ì¼ ì—°ì†**")
            res = get_consecutive_buys(df, p)
            if not res.empty:
                # Show Code/Name and Total Sum
                show = res[['Total_NetBuy']].reset_index().rename(columns={
                    'Code': 'ì¢…ëª©ì½”ë“œ', 'Name': 'ì¢…ëª©ëª…', 'Total_NetBuy': 'ê¸°ê°„í•©ê³„(ì–µ)'
                })
                st.dataframe(show.style.format({'ê¸°ê°„í•©ê³„(ì–µ)': '{:,.2f} ì–µ'}))
            else:
                st.write("- í•´ë‹¹ ì—†ìŒ -")

# --- Tab 4: Individual ---
with tabs[3]:
    st.header("ê°œë³„ ì¢…ëª© ìƒì„¸ ë¶„ì„")
    
    # Search Box
    all_stocks = df[['Code', 'Name']].drop_duplicates()
    all_stocks['Label'] = all_stocks['Name'] + " (" + all_stocks['Code'] + ")"
    selection = st.selectbox("ì¢…ëª© ê²€ìƒ‰", all_stocks['Label'].unique())
    
    if selection:
        code = selection.split("(")[-1].strip(")")
        
        # Filter Data (Last 7 Days)
        dates = get_sorted_dates(df)[:7]
        target = df[(df['Code'] == code) & (df['Date'].isin(dates))].sort_values('Date')
        
        if not target.empty:
            st.subheader(f"{selection}")
            
            # Metrics
            total_buy = target['NetBuyAmt_100M'].sum()
            col1, col2 = st.columns(2)
            col1.metric("ìµœê·¼ 7ì¼ ìŠ¤ë§ˆíŠ¸ ìˆœë§¤ìˆ˜ í•©ê³„", f"{total_buy:,.2f} ì–µ")
            
            # Chart
            fig = px.bar(
                target, x='Date', y='NetBuyAmt_100M',
                title="ì¼ë³„ ìŠ¤ë§ˆíŠ¸ ìˆœë§¤ìˆ˜ ì¶”ì´ (ë‹¨ìœ„: ì–µ)",
                text_auto='.2f',
                color='NetBuyAmt_100M',
                color_continuous_scale='Bluered',
                labels={'Date': 'ë‚ ì§œ', 'NetBuyAmt_100M': 'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Table
            target_disp = target[['Date', 'NetBuyAmt_100M', 'BuyVol', 'SellVol', 'NetBuyAmt']].rename(columns={
                'Date': 'ë‚ ì§œ',
                'NetBuyAmt_100M': 'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)',
                'BuyVol': 'ë§¤ìˆ˜ëŸ‰',
                'SellVol': 'ë§¤ë„ëŸ‰',
                'NetBuyAmt': 'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì›)'
            })
            
            st.dataframe(
                target_disp.style.format({
                    'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì–µ)': '{:,.2f} ì–µ',
                    'ë§¤ìˆ˜ëŸ‰': '{:,.0f}',
                    'ë§¤ë„ëŸ‰': '{:,.0f}', 
                    'ìˆœë§¤ìˆ˜ëŒ€ê¸ˆ(ì›)': '{:,.0f}'
                })
            )
        else:
            st.info("ìµœê·¼ 7ì¼ê°„ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
